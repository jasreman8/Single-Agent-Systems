{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jasreman8/Single-Agent-Systems/blob/main/Self_Reflective_RAG_Agent_Using_LangGraph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning Objectives\n",
        "\n",
        "- Construct Agentic Workflows: Understand how to build multi-step, stateful agent internal mechanisms using LangGraph's StateGraph, nodes, and edges.\n",
        "- Implement Custom RAG Logic: Learn to integrate core RAG components (retriever, generator) with custom enhancements like relevance checking and query rewriting within a graph structure.\n",
        "- Control Agent Flow: Utilize conditional edges (`add_conditional_edges`) based on tool usage (`tools_condition`) and custom logic (LLM-based relevance grading) to direct the agent's execution path."
      ],
      "metadata": {
        "id": "q9sFsyU4UfYD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "yG6pXoPHUaMS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hOebHaLQSVfj"
      },
      "outputs": [],
      "source": [
        "!pip install -q openai==1.66.3 \\\n",
        "                langchain==0.3.20 \\\n",
        "                langchain-openai==0.3.9 \\\n",
        "                langchain-community==0.3.19 \\\n",
        "                langchain-chroma==0.2.2 \\\n",
        "                langgraph==0.3.21 \\\n",
        "                grandalf==0.8 \\\n",
        "                chromadb==0.6.3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import chromadb\n",
        "\n",
        "from typing import Annotated, Sequence, Literal, TypedDict\n",
        "\n",
        "from langchain import hub\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "from langchain.tools.retriever import create_retriever_tool\n",
        "\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "\n",
        "from langgraph.graph import START, END, StateGraph\n",
        "from langgraph.prebuilt import tools_condition, ToolNode\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "#Vector databases store embeddings that capture semantic meaning, unlike relational databases that store structured data."
      ],
      "metadata": {
        "id": "jEjy6ic3OQUK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hide warnings/logs from Chroma\n",
        "# This code mutes the following telemetry error in ChromaDB:\n",
        "# ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
        "import logging\n",
        "logging.getLogger(\"chromadb\").setLevel(logging.CRITICAL)"
      ],
      "metadata": {
        "id": "y29z4cyMAdis"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = userdata.get('OPEN_API_KEY')\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    api_key=openai_api_key,\n",
        "    base_url=\"https://aibe.mygreatlearning.com/openai/v1\",\n",
        "    model='gpt-4o-mini',\n",
        "    temperature=0\n",
        ")\n",
        "# We are building a language model for reasoning and text-generation.  (Temp = 0 --> consistent and deterministic responses and not creative)\n",
        "\n",
        "embedding_model = OpenAIEmbeddings(\n",
        "    api_key=openai_api_key,\n",
        "    base_url=\"https://aibe.mygreatlearning.com/openai/v1\",\n",
        "    model=\"text-embedding-3-small\"\n",
        ")\n",
        "# We are building an embedding model for understanding the semantic meaning of text."
      ],
      "metadata": {
        "id": "Nts8JbriOWTx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Business Scenario"
      ],
      "metadata": {
        "id": "nP0G18G2MyrC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A RAG agent is highly useful for internal corporate knowledge base querying where accuracy and relevance are paramount. Imagine employees needing specific information from extensive technical manuals, financial reports (like the Tesla 10Ks used here), or HR policy documents.\n",
        "\n",
        "- **Problem:** Simple keyword searches or basic RAG might return irrelevant sections if the employee's query is slightly ambiguous or doesn't use the exact terminology found in the documents. This leads to wasted time and potentially incorrect information.\n",
        "\n",
        "- **Solution:** This agentic workflow ensures that retrieved document sections are first checked for relevance against the user's actual question. If relevant, a precise answer is generated. If not, the agent attempts to rewrite the query to better capture the user's intent and retries the retrieval process. This significantly increases the reliability and accuracy of answers derived from the company's specific knowledge sources."
      ],
      "metadata": {
        "id": "4mS_XZuiM2nM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation Roadmap"
      ],
      "metadata": {
        "id": "Uhc3yaFRNEyw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal is to build a RAG agent where the internal decision-making process is explicitly defined using LangGraph, providing fine-grained control over the workflow, particularly regarding context relevance.\n",
        "\n",
        "1. Component Preparation:\n",
        "\n",
        "    - Initialize core AI components: A language model (LLM) for reasoning and text generation, and an embedding model for understanding text semantics.\n",
        "\n",
        "    - Establish connection to the knowledge source: Set up access to the vector database containing the relevant document embeddings (e.g., Tesla 10K filings).\n",
        "\n",
        "    - Define the retrieval capability: Create a retriever mechanism configured to search the vector database based on semantic similarity. Package this retriever as a distinct \"tool\" the agent can choose to use.\n",
        "\n",
        "2. Workflow State Definition:\n",
        "\n",
        "    - Design a structure to hold the state of the conversation as it progresses. This state must primarily track the sequence of interactions (messages) between the user and the agent, including intermediate results like tool outputs. Ensure new messages are appended to maintain history.\n",
        "\n",
        "3. Core Workflow Structure (Conceptual Graph):\n",
        "\n",
        "    - Define the key processing steps (conceptual \"nodes\") and the transitions (conceptual \"edges\") between them.\n",
        "\n",
        "4. Planning / Decision Step:\n",
        "\n",
        "    - Implement the initial processing step after receiving input.\n",
        "\n",
        "    - This step uses the LLM, informed about the available retrieval tool, to analyze the latest user query within the context of the conversation history.\n",
        "\n",
        "    - The LLM's primary goal here is to decide if using the retrieval tool is the necessary next action to address the query.\n",
        "\n",
        "    - The output of this step should indicate the chosen action (e.g., signal intent to use the tool, or provide a direct response).\n",
        "\n",
        "5. Tool Execution Branching:\n",
        "\n",
        "    - Implement logic to check the outcome of the Planning step.\n",
        "\n",
        "    - If the Planning step signaled the intent to use the retrieval tool, direct the workflow to the Retrieval step.\n",
        "\n",
        "    - If no tool use was intended (e.g., the LLM generated a direct answer), terminate the workflow.\n",
        "\n",
        "6. Document Retrieval Step:\n",
        "\n",
        "    - Implement the step that executes the retrieval tool/capability defined in Step 1.\n",
        "\n",
        "    - Capture the documents returned by the retriever and add them (e.g., as a specific message type) to the workflow state.\n",
        "\n",
        "7. Relevance Assessment Step (Decision Point):\n",
        "\n",
        "    - Implement a critical checkpoint immediately after retrieval.\n",
        "\n",
        "    - This step uses the LLM to compare the content of the just-retrieved documents against the user's original query (preserved in the state).\n",
        "\n",
        "    - The goal is to determine if the retrieved information is semantically relevant to answering the question.\n",
        "\n",
        "    - The output must be a clear signal: \"Relevant\" or \"Not Relevant\".\n",
        "\n",
        "8. Conditional Flow based on Relevance:\n",
        "\n",
        "    - Implement transition logic based on the Relevance Assessment outcome:\n",
        "\n",
        "        - If \"Relevant,\" direct the workflow to the Final Answer Generation step.\n",
        "\n",
        "        - If \"Not Relevant,\" direct the workflow to the Query Rewriting step.\n",
        "\n",
        "9. Final Answer Generation Step:\n",
        "\n",
        "    - Implement the step responsible for synthesizing the final response.\n",
        "\n",
        "    - This step uses the LLM, providing it with the validated relevant documents from the state and the original user query.\n",
        "\n",
        "    - Generate the final answer and add it to the workflow state.\n",
        "\n",
        "    - Terminate the workflow successfully.\n",
        "\n",
        "10. Query Rewriting Step:\n",
        "\n",
        "    - Implement the self-correction mechanism.\n",
        "\n",
        "    - This step uses the LLM, instructing it to rephrase or clarify the original user query based on the knowledge that the previous retrieval attempt failed to find relevant information.\n",
        "\n",
        "    - The output should be the rewritten query. Update the workflow state to reflect this new query (potentially replacing or marking the old one).\n",
        "\n",
        "    - Direct the workflow to loop back to the Planning / Decision Step (Step 4) to process the rewritten query."
      ],
      "metadata": {
        "id": "-WfkXcJ_N2Ev"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector Store Setup"
      ],
      "metadata": {
        "id": "ZD4Bl-7gT3it"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ! unzip tesla_db.zip"
      ],
      "metadata": {
        "id": "hLuW1RN8qLTx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chromadb_client = chromadb.PersistentClient(\n",
        "    path='./tesla_db'\n",
        ")"
      ],
      "metadata": {
        "id": "chwX69krjgQm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tesla_10k_collection = 'tesla-10k-2019-to-2023'"
      ],
      "metadata": {
        "id": "vNNfojHIjlUE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    chromadb_client.get_collection(tesla_10k_collection)\n",
        "    print(f\"Collection '{tesla_10k_collection}' found.\")\n",
        "except Exception:\n",
        "    print(f\"Warning: Collection '{tesla_10k_collection}' not found in '{chromadb_client.path}'. Ensure it exists and contains data.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nhs7kta4joCX",
        "outputId": "8815ac74-adbf-484b-999b-f47f639d1214"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collection 'tesla-10k-2019-to-2023' found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore_persisted = Chroma(\n",
        "    collection_name=tesla_10k_collection,\n",
        "    embedding_function=embedding_model,\n",
        "    client=chromadb_client,\n",
        ")"
      ],
      "metadata": {
        "id": "m0mwVtIKjofT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above code block:\n",
        "\n",
        "- `! unzip tesla_db.zip`: Unzips a local file containing the pre-built Chroma database files (this assumes `tesla_db.zip` exists in the Colab environment).\n",
        "- `chromadb.PersistentClient`: Creates a client connection to the persistent Chroma database stored in the `./tesla_db` directory.\n",
        "- Checks if the target collection (`tesla_10k_collection`) exists within the database using `get_collection` and prints a status message.\n",
        "- `Chroma(...)`: Creates a LangChain Chroma vector store object, linking it to the existing collection name, the embedding model, and the ChromaDB client."
      ],
      "metadata": {
        "id": "W2S5jmU-T9qa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore_persisted.as_retriever(\n",
        "    search_type='similarity',\n",
        "    search_kwargs={'k': 5}\n",
        ")\n",
        "# This retriever will provide FIVE most semantically similar document chunks to any query that we provide."
      ],
      "metadata": {
        "id": "8oE3_HFQjrLa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_tool = create_retriever_tool(\n",
        "    retriever, # The retriever is now wrapped into a tool with a very specific description that guides the agent's behavior.\n",
        "    \"retrieve_tesla_10k_documents\",\n",
        "    \"\"\"\n",
        "    Search and return information mentioned in Tesla 10K documents from 2019 to 2023.\n",
        "    Use this tool ONLY to find specific financial figures, operational details, risks,\n",
        "    or other factual data directly reported in Tesla's 10-K filings.\n",
        "    Do NOT use this tool for general knowledge questions about Tesla.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "tools = [retriever_tool]"
      ],
      "metadata": {
        "id": "ZQCdt1lkjuUN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above code block:\n",
        "\n",
        "- `vectorstore_persisted.as_retriever(...)`: Creates a LangChain retriever object from the vector store. It's configured for similarity search and to retrieve the top 5 (k=5) most similar documents.\n",
        "- `create_retriever_tool(...)`: Wraps the retriever into a LangChain Tool. This gives it a name (`retrieve_tesla_10k_documents`) and a description, which the LLM uses to understand when and how to use this tool. The description guides the LLM to use it only for specific factual queries from the 10-K documents.\n",
        "- `tools = [retriever_tool]`: Defines a list containing the tool(s) the agent can use."
      ],
      "metadata": {
        "id": "2t5cU9WWUKRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent State Definition"
      ],
      "metadata": {
        "id": "rBK6yZcpUzIu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " - The agent stage structure defines the sequence in which an agent plans, executes, and reflects within its workflow. Common stages include planning, tool execution, reasoning, reflection, and response."
      ],
      "metadata": {
        "id": "MpZhf9DKlD8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentState(TypedDict):\n",
        "    # The add_messages function defines how an update should be processed\n",
        "    # Default is to replace. add_messages says \"append\"\n",
        "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
        "\n",
        "# This class forms the foundation of our entire agent's memory system."
      ],
      "metadata": {
        "id": "vtkS_il02Wsd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above code block:\n",
        "- `class AgentState(TypedDict): ...`: Defines the structure of the data that will persist and be passed between nodes in the graph.\n",
        "\n",
        "- `messages: Annotated[Sequence[BaseMessage], add_messages]`: Defines a key messages which holds a sequence of LangChain `BaseMessage` objects. The Annotated type hint with `add_messages` tells LangGraph that whenever a node returns a list of messages for this key, they should be appended to the existing list in the state, rather than replacing it."
      ],
      "metadata": {
        "id": "OH--R9cEUndb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-configured LLM and Chains"
      ],
      "metadata": {
        "id": "oeD7LqyTU1tD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the code blocks below, we define a series of chains that handle LLM call executions to grade document relevance, rewrite queries and generate RAG outputs.\n",
        "\n",
        "Specifically:\n",
        "- `llm_with_tools = llm.bind_tools(tools):` Creates a version of the LLM that is aware of the available tools. This is used by the `plan` node so the LLM can decide to call the `retriever_tool`.\n",
        "- `rewrite_prompt_template`, `rewrite_chain`: Defines the prompt and chain specifically for rewriting the user's query if the initial retrieval fails the relevance check. It uses the base llm and a `StrOutputParser` to get just the rewritten text.\n",
        "\n",
        "- `rag_prompt_template`, `rag_chain`: Defines the prompt (pulled from LangChain Hub) and chain for generating the final answer, taking context (retrieved documents) and the question as input. It uses the base llm and `StrOutputParser`.\n",
        "\n",
        "- `GradeDocuments`, `structured_llm_grader`, `grade_prompt_template`, `grading_chain`: Defines the components for the relevance check. `GradeDocuments` is a Pydantic model defining the desired JSON output structure ('yes'/'no'). `structured_llm_grader` is an LLM configured to output data matching this structure. The grade_prompt_template instructs the grader, and the `grading_chain` combines the prompt and the structured LLM. Defining these globally makes the grade_documents edge function cleaner and more efficient."
      ],
      "metadata": {
        "id": "uRrDiVrvabk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "# A language model predicts the next token based on probability distributions.\n",
        "# Modern LLMs like GPT are transformer-based and trained on trillions of tokens."
      ],
      "metadata": {
        "id": "TMpqfcgB-5bF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chain for query rewriting\n",
        "rewrite_prompt_template = PromptTemplate(\n",
        "    template=\"\"\"You are a query transformation assistant. Your task is to rewrite the user's original question \\\n",
        "based on the fact that the initial retrieval attempt failed to find relevant documents. \\\n",
        "Focus on clarifying the intent or broadening the scope slightly, while staying true to the core request. \\\n",
        "\\nOriginal Question: {question}\\\n",
        "\\nProvide ONLY the rewritten question:\"\"\",\n",
        "    input_variables=[\"question\"],\n",
        ")\n",
        "\n",
        "rewrite_chain = rewrite_prompt_template | llm | StrOutputParser()"
      ],
      "metadata": {
        "id": "DwpViLel_f9L"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chain for final answer generation\n",
        "rag_prompt_template = hub.pull(\"rlm/rag-prompt\")\n",
        "# Pulling a pre-built prompt template from LangChain Hub that's specifically designed for RAG tasks.\n",
        "\n",
        "rag_chain = rag_prompt_template | llm | StrOutputParser()"
      ],
      "metadata": {
        "id": "3qTwomzY_7FT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11b61bc0-c648-452d-af31-c66560a2eeb4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " - Document structure ensures organized retrieval and chunking of data. Chunks with metadata (source, timestamp, tags) improve search and context injection."
      ],
      "metadata": {
        "id": "CbDmgRFfnmc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pydantic model for the grading output\n",
        "class GradeDocuments(BaseModel):\n",
        "    \"\"\"Binary score for relevance check.\"\"\"\n",
        "    binary_score: str = Field(description=\"Relevance score 'yes' or 'no'\")\n",
        "\n",
        "# LLM with structured output for grading\n",
        "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
        "\n",
        "# Chain for grading documents\n",
        "grade_prompt_template = PromptTemplate(\n",
        "    template=\"\"\"You are a grader assessing relevance of retrieved documents to a user question.\n",
        "Here are the retrieved documents:\\n\\n{context}\\n\\n\n",
        "Here is the user question: {question}\n",
        "If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant.\n",
        "Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\",\n",
        "    input_variables=[\"context\", \"question\"],\n",
        ")\n",
        "\n",
        "grading_chain = grade_prompt_template | structured_llm_grader"
      ],
      "metadata": {
        "id": "-hV9nNcEAQCL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Node Functions\n",
        "\n",
        "In this section, we implement the key functions (`plan`, `generate` and `rewrite`) that make up the internal wiring of the agent.\n",
        "\n",
        "- These Python functions define the actions performed at specific points (nodes) in the graph.\n",
        "- Each function takes the current state (an AgentState dictionary) as input.\n",
        "- `plan`: Uses `llm_with_tools` to decide the next action based on the messages in the state. Returns the `AIMessage` (which might include a tool call) to be added to the state.\n",
        "\n",
        "- `rewrite`: Extracts the original question, uses the `rewrite_chain` to get a new question, and returns a new HumanMessage containing only the rewritten query. This resets the context for the next planning step.\n",
        "\n",
        "- `generate`: Extracts the question and the retrieved document content (from the last `ToolMessage`), uses the `rag_chain` to generate the final answer, and returns it as an `AIMessage`.\n",
        "\n",
        "- Each node returns a dictionary mapping state keys (only messages here) to the new value(s) to be merged into the state according to the `AgentState` annotations."
      ],
      "metadata": {
        "id": "XHIEvSvkKr4T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " A retriever is used to fetch relevant documents or data from a knowledge base. It works with vector databases to return the most contextually relevant information."
      ],
      "metadata": {
        "id": "uYtYml73rB6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plan(state: AgentState):\n",
        "    \"\"\"\n",
        "    Invokes the retriever to retrieve documents based on the current state. Given\n",
        "    the question, it will decide to retrieve using the retriever tool, or simply end.\n",
        "\n",
        "    Args:\n",
        "        state (messages): The current state\n",
        "\n",
        "    Returns:\n",
        "        dict: The updated state with the agent response appended to messages\n",
        "    \"\"\"\n",
        "    print(\"---PLAN RETRIEVAL---\")\n",
        "    messages = state[\"messages\"]\n",
        "\n",
        "    response = llm_with_tools.invoke(messages)\n",
        "\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "# Agent's central intelligence hub."
      ],
      "metadata": {
        "id": "u4MGjpyG-js7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rewrite(state: AgentState):\n",
        "    \"\"\"\n",
        "    Transform the query to produce a better question.\n",
        "\n",
        "    Args:\n",
        "        state (messages): The current state\n",
        "\n",
        "    Returns:\n",
        "        dict: The updated state with re-phrased question\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---REWRITE QUERY---\")\n",
        "    messages = state[\"messages\"]\n",
        "    current_question = messages[0].content\n",
        "\n",
        "    rewritten_question = rewrite_chain.invoke({\"question\": current_question})\n",
        "\n",
        "    return {\"messages\": [HumanMessage(content=rewritten_question)]}\n",
        "\n",
        "# Query improvement mechanism."
      ],
      "metadata": {
        "id": "vPMdC4E6_I7n"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(state: AgentState):\n",
        "    \"\"\"\n",
        "    Generate answer\n",
        "\n",
        "    Args:\n",
        "        state (messages): The current state\n",
        "\n",
        "    Returns:\n",
        "         dict: The updated state with re-phrased question\n",
        "    \"\"\"\n",
        "    print(\"---GENERATE ANSWER---\")\n",
        "    messages = state[\"messages\"]\n",
        "    question = messages[0].content\n",
        "\n",
        "    last_message = messages[-1]\n",
        "\n",
        "    docs_content = last_message.content\n",
        "\n",
        "    # Use the globally defined RAG chain\n",
        "    response = rag_chain.invoke({\"context\": docs_content, \"question\": question})\n",
        "    # The response gets formatted as an AI message, and then it's also added to the conversation state.\n",
        "\n",
        "    # Return the response as an AIMessage\n",
        "    return {\"messages\": [AIMessage(content=response)]}"
      ],
      "metadata": {
        "id": "N2ZjquQj_ui8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Edge Function\n",
        "\n",
        "The function defined in the code block below implements the logic for a conditional edge. It determines which node the graph should transition to after the retrieve node completes.\n",
        "\n",
        "- It takes the current state as input.\n",
        "- It extracts the question and the retrieved documents' content.\n",
        "- It uses the globally defined grading_chain to assess relevance.\n",
        "- It returns a string (\"generate\" or \"rewrite\") which corresponds to the key in the conditional edge mapping defined later, thus directing the flow to the appropriate next node. Includes basic error handling."
      ],
      "metadata": {
        "id": "UYQer6Y3e2zj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Edge functions in LangGraph define the connections (edges) between nodes in the workflow graph/ They help decide which node to run next based on conditions or outputs of the previous step."
      ],
      "metadata": {
        "id": "mhrgc7QhsDCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision between rewriting the query and generating the final answer\n",
        "\n",
        "def grade_documents(state) -> Literal[\"generate\", \"rewrite\"]:\n",
        "    \"\"\"\n",
        "    Determines whether the retrieved documents are relevant to the question.\n",
        "\n",
        "    Args:\n",
        "        state (messages): The current state\n",
        "\n",
        "    Returns:\n",
        "        str: A decision for whether the documents are relevant or not\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---CHECK RELEVANCE---\")\n",
        "\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "\n",
        "    question = messages[0].content\n",
        "    docs_content = last_message.content\n",
        "\n",
        "    # Use the globally defined grading chain\n",
        "    try:\n",
        "        scored_result = grading_chain.invoke({\"question\": question, \"context\": docs_content})\n",
        "        score = scored_result.binary_score.lower()\n",
        "        print(f\"--- Relevance Score: {score} ---\")\n",
        "        if score == \"yes\":\n",
        "            print(\"---DECISION: DOCS RELEVANT---\")\n",
        "            return \"generate\"\n",
        "        else:\n",
        "            print(\"---DECISION: DOCS NOT RELEVANT---\")\n",
        "            return \"rewrite\"\n",
        "    except Exception as e:\n",
        "        print(f\"--- Error during grading: {e} ---\")\n",
        "        return \"rewrite\" # Default to rewrite on grading error"
      ],
      "metadata": {
        "id": "TcK8NdRhAHeD"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph Construction"
      ],
      "metadata": {
        "id": "qVjzuBHffGfp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the code block below, we implement an execution graph depicting the internal workflow of the RAG agent.\n",
        "\n",
        "Specifically:\n",
        "\n",
        "- `workflow = StateGraph(AgentState)`: Initializes a state machine graph configured to manage the AgentState.\n",
        "- `workflow.add_node(...)`: Adds the defined functions (plan, rewrite, generate) and the pre-built ToolNode (retrieve) as nodes in the graph.\n",
        "- `workflow.add_edge(START, \"plan\")`: Sets the entry point of the graph to the plan node.\n",
        "- `workflow.add_conditional_edges(\"plan\", tools_condition, ...)`: Defines the transition from the plan node. It uses the `tools_condition` function to check the output of plan. If `tools_condition` detects a tool call, flow goes to the \"retrieve\" node; otherwise, flow goes to END.\n",
        "- `workflow.add_conditional_edges(\"retrieve\", grade_documents, ...)`: Defines the transition from the retrieve node using our custom grade_documents function. Based on the return value (\"generate\" or \"rewrite\"), it routes to the respective node.\n",
        "- `workflow.add_edge(\"rewrite\", \"plan\")`: Defines a fixed edge causing the workflow to loop back to the plan node after a query rewrite.\n",
        "- `workflow.add_edge(\"generate\", END)`: Defines a fixed edge causing the workflow to terminate after generating the final answer."
      ],
      "metadata": {
        "id": "uXOSycyWfKgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a new graph\n",
        "workflow = StateGraph(AgentState)"
      ],
      "metadata": {
        "id": "dq5q8IpvAo4z"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " - Agent stage structure defines the phases an agent goes through while reasoning, typically including planning (deciding the next step), action (invoking a tool or function), observation (receiving results), and reflection (rethinking or updating the plan if needed)."
      ],
      "metadata": {
        "id": "As96Jwsws6EU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the nodes we will cycle between\n",
        "workflow.add_node(\"plan\", plan)  # central planner\n",
        "retrieve = ToolNode([retriever_tool])\n",
        "workflow.add_node(\"retrieve\", retrieve)  # retrieval\n",
        "workflow.add_node(\"rewrite\", rewrite)  # Re-writing the question\n",
        "workflow.add_node(\n",
        "    \"generate\", generate\n",
        ")  # Generating a response after we know the documents are relevant\n",
        "\n",
        "# Call agent node to decide to retrieve or not\n",
        "\n",
        "workflow.add_edge(START, \"plan\")\n",
        "\n",
        "# Decide whether to retrieve\n",
        "workflow.add_conditional_edges(\n",
        "    \"plan\",\n",
        "    # Assess agent decision\n",
        "    tools_condition,\n",
        "    {\n",
        "        # Translate the condition outputs to nodes in our graph\n",
        "        \"tools\": \"retrieve\",\n",
        "        END: END\n",
        "    }\n",
        ")\n",
        "\n",
        "# Edges taken after the `action` node is called.\n",
        "workflow.add_conditional_edges(\n",
        "    \"retrieve\",\n",
        "    # Assess agent decision\n",
        "    grade_documents\n",
        ")\n",
        "\n",
        "workflow.add_edge(\"rewrite\", \"plan\")\n",
        "workflow.add_edge(\"generate\", END)"
      ],
      "metadata": {
        "id": "QXFl4hztAtV0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15345083-8b96-43e0-bea5-be8e4348d733"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7840c01aa780>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph Compilation and Invocation"
      ],
      "metadata": {
        "id": "VKxH2gfUfodZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent_workflow = workflow.compile()"
      ],
      "metadata": {
        "id": "LGUgXeMLBAxB"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAATsAAAHICAYAAAAx2k1wAAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAABO6ADAAQAAAABAAAByAAAAAAy9wbOAABAAElEQVR4Ae2dB3hUxRbH/+mdhISEFnpvUqQJPKVIVREpioCIgo0nT/QhWMHe9dl7QRQBC0VQuhVEikqT3ltoARLSSXn3DO6yCcnmbrLl7t3/fF92b5k7c+Y3N2dnzsyc8SvQAhhIgARIwOQE/E1ePhaPBEiABBQBKju+CCRAAj5BgMrOJ6qZhSQBEqCy4ztAAiTgEwSo7HyimllIEiABKju+AyRAAj5BINAnSukDhTx+MAfpqeeQnpKL3OwCZGflm7bUQSF+CAjwQ0R0ICIqBCK+RggCg/xMW14WzDkE/DjPzjkgPZHKrg3p2LspDXs2p6N20wicy8nX/vkDEFs5BDnZeZ4QyS15BocGIDX5vGJPT83F8UPZqFonFHWaRaBxuwoICWOHxS0V4WWZUNl5WYWJuNv/OIvf5p9ErcYRqF4/DHWaRyA41Lf/wQ/uyMTezWk4ui8LNRqF47Kr4rywZimyKwlQ2bmSrpPTTk/Nw9LPjyJc67p1viZOdeOcnIUpkvtj2Wms+j4ZvUZUQcM2kaYoEwtRfgJUduVn6JYUDmzPwLIvjuG6fyeiYkKQW/L05kxkEeQvs08gKNgfnbQfBgYSoLLzgnfghGaT+m1BMq69s5oXSGssEf9Yfho52mANu7XGqhdPSOPbhh5PEHcwz51/pmHltyep6BzkZol+aY+KqnW3+NOjlkv89lECVHYGrvjTx3KwZkkyBoytbmApjS9a254VER0fhLVLThlfWEroMgJUdi5DW/6Ef/rqBIZNqlX+hJgCOvaLQ1Z6PvZvzSANHyVAZWfQipeua62m4fDjXFmn1dAl/4rGz9+ccFp6TMi7CFDZGbC+sjLysWV1Ktp0r2hA6bxXpOhKQUhsEIa/f0/13kJQ8jIToLIrMzrXPbj+pzO4YlCC6zLw4ZQ7X1MJezam+TAB3y06lZ0B637zyjOoqa0CMFqYNWsWHnvsMaeINXHiRMyfP98paTmSSEi4v5qKkrQny5HHGNcEBKjsDFaJSXuzEJMQjNAI41XNli1bnEbLmWk5KpQsr9ujLS1j8C0CnFRssPpeu+Q0wiL90bxTtNsl+/PPP/H2229j586dkH2YGjZsiLvvvhutWrXC6NGjsWHDBqtM06dPR6NGjbBo0SJMmzYNBw8eRHBwMFq2bIn77rsPiYmJKu7MmTPx8ccf4+GHH8aTTz6Jvn37YsaMGdZ0IiMj8dNPP1nP3XFw9lQufvzqOPrfwUna7uBtlDyM13wwChkPyXHiUBbCI93veSszMxPjx49H/fr1MXXqVPUnx+PGjUNaWhpee+01NG7cGL169cKyZctUvI0bN+KRRx5B9+7dlQJ76623kJGRgQceeMBKLzAwEFlZWfjyyy/xxBNPYNiwYfj+++/V/fvvvx/z5s2zxnXXQVRsIA5s4xQUd/E2Sj7u/68ySskNKkfG2TxtoX+A26U7evSoUlT9+vVDnTp1VP4TJkxAnz59IAorNDRUfUvrLSYmRt2vV68epIUnSjEg4LzMN9xwA0SJpaSkIDo6Wj0jCvDGG29Ep06d1HPZ2dnqOzw8XMVRJ27+CI8KQIbmWMETrN1cVGb3DwEqO4O9Chmaf7bwKPdXS82aNSF/Dz30EAYPHowuXbooJSZd2JJCREQEdu3ahVdeeQWHDh1SLbjc3FwVPTU1tZAia968eUnJeOS6eI4RX3hUdh7B75FM2Y31CPaSMw0M8oe/+xt2qmX24YcfomfPnpg7dy6GDh2KAQMGYOnSpSUK+80332DKlCnKpvf666/jiy++wKRJk4qNL7Y5IwXx/8ft4Y1UI66XhcrO9YwdyiFQczkufus8EWJjY3HPPfcoZff1118rJfbggw9ix44dxYojgxNt27bFXXfdBenSVq5cGZaWXbEPGOhiyskc5dXZQCJRFBcToLJzMWBHk4/QurDSlXV3kG6o7aho7dq1VZfWT1uvVpKyO3funNV+Z5FXFKAEGc01cpAfFOnKMvgOASo7g9V1fGIIsjPdv1nOkSNHIBN9P/vsM+zbtw/79+9XU0Zk4KFFixaKUlRUFLZv367+zpw5A7HDrVmzBps3b4Y8//TTT6NKlSoqrsyjswxEFEUcEhIC+ZOpLpKeu1uDMjBRqwnXHRetF7OfU9kZrIar1g3DtnXuX7vZvn17TJ48Gd999x2GDx+OkSNHKkX28ssvo1at855XxI53/PhxNedu69atGDNmjOrqSjf21ltvVd1YmYrSoUMHPP744/j1119LpDtq1ChlDxw7dixk2os7w25tuViFWHp7didzI+TFScVGqIUiMrwzcTdue7outwcswsVZp/PePYLW3WIMuSTPWWVkOhcTYMvuYiYev9JCWz1xcLt7WzseL7SbBMjXxn7y8wqo6NzE20jZ0EJrpNr4R5YWXaLx7XtHtC0SS3fc+dRTT6kVDfaKIYMFMtBgL0g6MrfOE6FHjx7Iyyt5BNpyzzJxuSQZZWWHTIC2F1Z9p/kJ1Ox1DL5HgN1Yg9b5D7OOo3KtUDTrWMGuhDJQICsU7IWcnBy1btVeHJl2IqskPBGSkpLsjt6K/KKwZVDDXqhatapdpS5+Aj97ep8yEdhLh/fMSYDKzqD1Kv+YskfsNbdzsbqzqmjNolMQB56N2kY5K0mm40UEaLMzaGWFan7XWnWtiLnvHDaohN4l1qaVKchIy6Oi865qc6q0VHZOxencxGo0DEPtJhFYNv2YcxP2sdR2b0jHjj/OouvgeB8rOYtrS4DdWFsaBj3euzkdezalo8eNCQaV0Lhi7dD23d2zKQ19bj4/2dm4klIyVxNgy87VhJ2QvnjWrVI7FF+/dgi5OcZehuWE4jotiT+WncZeKjqn8fT2hNiy86IaPLovCzJKW7dFhNoH1YtEd6uoO/48i9/mJ0O2TuQObW5Fb+jMqOwMXT3FCKc17NZpLZbVi5LR9spYNTm2al3PTBkpRjqPXUo5eQ7S3T+0MxNBoX6QXcQiY+zPufOYsMzYIwSo7DyCvfyZ5mu+Ajb8ckZtC3jqaA4at4tS/tkiNE8e0ZWCkZfrfmcC5S+VvhQCg/xw9kwu0lNylbfh45ore1kZUadZBBq1q4D46sH6EmIsnyJAZWeC6s7W5uQd3p2JtH8UgHhXEkXgrrB27Vo0a9YM4mbdHSFMc6leoOnyiOgAzSddIBJqhKBiZSo4d7D35jyo7Ly59gwiu7hxf+mllyA+8BhIwKgEOBpr1JqhXCRAAk4lQGXnVJxMjARIwKgEqOyMWjOUiwRIwKkEqOycipOJkQAJGJUAlZ1Ra4ZykQAJOJUAlZ1TcTIxEiABoxKgsjNqzVAuEiABpxKgsnMqTiZGAiRgVAJUdkatGcpFAiTgVAJUdk7FycRIgASMSoDKzqg1Q7lIgAScSoDKzqk4mRgJkIBRCVDZGbVmKBcJkIBTCVDZORUnEyMBEjAqASo7o9YM5SIBEnAqASo7p+JkYiRAAkYlQGVn1JqhXCRAAk4lQGXnVJxMjARIwKgEqOyMWjOUiwRIwKkEqOycipOJkQAJGJUAlZ1Ra4ZykQAJOJUAlZ1TcTIxEiABoxKgsjNqzVAuEiABpxKgsnMqTt9MrEKFCr5ZcJbaqwhQ2XlVdRlT2NTUVGMKRqlIwIYAlZ0NDB6SAAmYlwCVnXnrliUjARKwIUBlZwODhyRAAuYlQGVn3rplyUiABGwIUNnZwOAhCZCAeQlQ2Zm3blkyEiABGwJUdjYweEgCJGBeAlR25q1blowESMCGAJWdDQwekgAJmJcAlZ1565YlIwESsCFAZWcDg4ckQALmJUBlZ966ZclIgARsCFDZ2cDgIQmQgHkJUNmZt25ZMhIgARsCVHY2MHhIAiRgXgJ+BVowb/FYMlcRaNOmDfz8/FTy8m37GtWqVQuzZ892VdZMlwTKRIAtuzJh40Oi0ETJ2So8OY6MjMQdd9xBQCRgOAJUdoarEu8QqEePHlZFZytxjRo10Lt3b9tLPCYBQxCgsjNENXifENdffz1EsdmGiIgIDB8+3PYSj0nAMASo7AxTFd4lSEJCAoq27qRr27dvX+8qCKX1GQJUdj5T1c4vqLTuatasqRKWVt3QoUOdnwlTJAEnEaCycxJIX0wmPj4eXbt2VbY7adX169fPFzGwzF5CINBL5KSYjhLQJhQdO5iN08dykJOV5+jTuuO3qTcAWxum4/LOl2Pjr2d0P+doxIBAP0TFBqFS1RCEVwhw9HHGJwFwnp0JX4JDOzOxeuEpnMvJR2KDCGSmu07ZuQtfSHgATh7K0lqR0MoUhna9Krora+ZjEgJUdiapSEsxju3Pxk9fn0DvUdUhrSEzhjXfn0BkxUB06EOFZ8b6dVWZaLNzFVkPpJt6KhcLpyah35hE0yo6wdq+XzykrH/95Lpusweqj1m6mACVnYsBuzP5dUtPoV3veHdm6bG82vWqhC2/pyLf+3voHmPoaxlT2ZmoxpP2ZqFCXJCJSlRyUQKC/JB3rgBnT58rORLvkIANASo7GxjefpibU6CNVPrOAHuFSsFIO5Pr7dVG+d1EgMrOTaDdkU22NsXEl1zY5J3LdwdW5mESAlR2JqlIFoMESMA+ASo7+3x4lwRIwCQEqOxMUpEsBgmQgH0CVHb2+fAuCZCASQhQ2ZmkIlkMEiAB+wSo7Ozz4V0SIAGTEKCyM0lFshgkQAL2CVDZ2efDuyRAAiYhQGVnkopkMUiABOwToLKzz4d3SYAETEKAys4kFclikAAJ2CdAZWefD+8WITB7ziz06Nm+yFWekoDxCVDZGb+OKCEJkIATCFDZOQEikyABEjA+Ad9xfmb8uvC4hLO+/AxfzJiKhx96Cm+/8wqOHUtCXGwljBp1J67s0adY+U6dSsY7772Kv/5ai7NnU5GQUAUDrxuK6wZcb43ff0B33HzTbTicdAi//LIcWVmZuOSSNphw3yOIjY2zxuMBCbiSAFt2rqTrZWkHBgYhLe0svv56Ol5+8R3Mm/MDunXrhWefm4xDhw8WW5rnnp+C7du34PEpL+Djj77E8GG34M23XsJvv/1ijR8cHIwvZk5F3Tr1MfOLBfjog1nYsWMrpn32gTUOD0jA1QSo7FxN2IvS99P2KczPz8dNI8YgLq4SREmN1FpkISEh+OGHxcWWZPz4B/Hi82+hWbNLUL1aIvr0vga1a9fFuj9XW+NLurVr1cXVV12HwMBAVK5cBZde2kEpSWskHpCAiwmwG+tiwN6YfIMGja1iBwUFaUqshtayO2C9Znvg7+ePGVqrbf2GP3DmzGkUFBQgPT0NdbRWnG2oV6+h7SkiI6OQqnV7GUjAXQSo7NxF2ovyCQ0NLSRtaFiY6t4Wuqid5OTk4N77bofcH3vXfahRoxYC/APwyKP3FY2qWodFL5pzV9uipeS5UQhQ2RmlJgwkR2ZmJsI0BWYJGRnpqKZ1UYuGv7dsxFFtEOO1/32gDTi0tt5OPZtiPeYBCRiFAG12RqkJA8mxQeuSWkJGRgYOHNiHGom1LJes39KykxAdHWO9tmnTem0U9yjYarMi4YFBCLBlZ5CKMIoYMoAgI6cREZFKiU37/EMlWvfuvS8Ssb5mhxOb3py5s9Sgxq7dO/DJJ++gXduOSkGKDS8mpuJFz/ECCXiCAFt2nqBu8DzH3PpvvP7GCxh921Bs3bIJTz7xMqpVrX6R1DJie/+EyVi9eiWG33StNkfvEzww6XEMGjQMR7Q5dRMmjr3oGV4gAU8R8NNGz3xpq1FPcXZLvu8/tAcD76mNkNCy/YbJute33n4Zy5eucYu85c1kyaeH0bFfLKrXv2BfLG+afN68BMr2X2FeHiwZCZCASQlQ2Zm0YlksEiCBwgSo7Arz8Omzgdfd4DVdWJ+uKBa+TASo7MqEjQ+RAAl4GwEqO2+rMcprJcCxNSsKHuggQGWnAxKjGJOAKLt7770Xy5YtM6aAlMpQBKjsDFUdFMYRAv7+/njqqae0CdAR6rHZs2dj7ty5jiTBuD5EgMrOhyrbjEUVRXfZZZeponXq1AmbNm3CkiVL1PnOnTvNWGSWqYwEuFysjOD4mPEIVKlSBY8++qhVsJkzZ2LDhg344osvlG8+6w0e+CQBtux8stp9o9Ci+F566SXlYy8tLQ0TJ05Uys83Ss9SFiVAZVeUCM9NRaB2bW35nOZpOTIyEr1798bSpUtV+Xbt2oUjR46YqqwsjH0CVHb2+fCuiQj06NEDEyZMUCWSwY077rgD3377rYlKyKLYI0CbnT06XnZP9o9g0Eegbt26mD9/Pg4dOqQeePbZZyF7ZfznP/9BeHi4vkQYy6sIsGXnVdVVvLDiRPOqq65CVEVtw5xzvuPEJkjz7hIUUr5XODHxvAdmsefVr18f+/fvV5ClxZeVlVU8cF71SgLle1O8ssjmEvro0aNITU3FRx99hAqx4Th5xHf+QQ9sS0d8YohTKjQgIACDBw9GkyZNVHpiz+vT5/xeuVR6TkHs8USo7DxeBWUTYN++fejSpQtkc5xKlSpBpl00aReFQzvSy5aglz21f2samnaooHU9XSP4nXfeiZ9++kklnpKSgn79+mHRokWuyYypuoUAlZ1bMDsvE8u+DzKaKCOLMTEX9n+o3yoSMfFBWLPwpPMyNGBKxw5k4e+VZ9D9hgS3SFe5cmXN3fwn1rx+/PFHLlGz0vCeA3oq9p66Uv9gn376KT777DO7Uq+YexKZGQUIjwrUunmhKMj3fjueX4AfUk7kIDsjD0d2p2PQfxIREOiiZp1duoCYDl599VW0bdtWdX3lXFrWDMYmQGVn7PpR0qWnp6v1n++++y6ke6UnHNyRiUM7M5ClKYfU5Fw9j5Q5zu5du1G9enVt/9jC+82WOcFiHgyPCkCwNhiRUCMUTTpEFRPD/ZfOnTunNhx67rnnsG3bNrz55ptqPp/7JWGOeghQ2emh5ME40n2KiopSLQgPilFi1rLwXlYpdOzYUX2XGNHkNzZv3qxad2I/feKJJzBw4EA0b97c5KX2ruLRZmfQ+srNzYUsZJdWnYwSGjXI+lMZrdy4caNPL8USxSaKTsKll15qNTVIF/f06dNGrT6fkovKzoDVLfYgmU5So0YN3H333QaU8LxIc+bM0faHPaBOTp06hWnTphlWVncKJnMen3/+eZVlXl4ehgwZglmzZrlTBOZVDAEqu2KgePKS2H2khRAbG6umlXhSltLylladZXRY4op7JfEywnCBgNgyxblomzZt1MUPP/wQr732mmqxX4jFI3cQoLJzB2UdeVimNtxyyy0YMWKEjic8G2XevHk4ePBgISGkdTd16tRC13hynkCDBg3UgdRtxYoVsX79enX+yy+/EJGbCFDZuQm0vWy6du1qNWZbvO7ai2+Ee9OnTy/UqrPItGXLFmW/s5zzuzABmQQ+cuRIdO7cWd3YsWMH2rdvr+ye0uVlcB0Bjsa6jq3dlM+cOaOmK8gopjcGkVsGUWQfCPmTRfTyJ/+wHTp0gEyTYdBHQJiJEweZyjJq1Cjceuut1qVq+lJgLD0EqOz0UHJyHPG0IS/1jBkzEB8f7+TU3Z+cjBbL9JPamu84hvIR2L17N37//XcMHz5c2T9lNF7czTOUnwC7seVnqDsFWc8qv+IyVUOM1mZQdLoLz4i6CNSrV08pOoksqzLkB1FWzUiQ3gBD2QlQ2ZWdnUNPLl68GP/9738h3jXElRADCZRGQNbkvvHGG9Z5lp9//rlaQSMDQQyOE6Cyc5yZQ09Y/KMFBQXhm2++cehZRiYBIWAZtJI5l2PGjIF4YZHw9ttvY/v27eqYH6UToLIrnVGZY4j3W8ueB927dy9zOnyQBCwExPlAnTp11GnNmjUh63IlyCT0zMxMdcyP4glQ2RXPpVxXpZshk21lbpX8EjOQgCsIXH311VbXUzIy3rNnT6t9zxX5eXuaVHZOrEEZfBD33sePH1f7lBp5TasTi82kDEBAVtysWLECl1xyiZJG3MqL92p6Wb5QOVR2F1iU+0g2cJHt+ho3blzutJgACZSFQOvWrdVjYjbJzs62elfmMj6Ayq4sb5TNMzIdwLI934ABAyDb9TGQgKcJyD65Y8eOhbyTEv766y/ISh1fHsmlsivnW/nUU095xVrWchaTj3s5AZnEvmDBAgQGnt89dfTo0dZWn5cXTbf4VHa6UV2IKOsZZc6TBFk50KpVqws3eUQCBiUgrb0KFSoo6e69917lL1FOZLK7tPzMHqjsHKxhGeKfMmUK+vbt6+CTjE4CxiEgzkbHjRunBBJP2G+99ZaatycXzDqocb5Na5w6MKwka9asQVxcHGRWuyzhYSABsxCQ91r87FnsedJr+fvvv/Hggw8iIcE9O7i5gyVbdjooy/6h4m+uVq1a3FBFBy9G8U4CMn1FgswNve666yAbhUsQJ61FfReqG172QWVnp8JWrVql7latWhXvvPOO1bhr5xHeIgFTELj88suttmix9UmXV1ZoyORlbw1UdiXU3DPPPIPVq1eru40aNSohFi+TgPkJyEoN2UVO1neLshNnoxbP2t5Ueiq7IrVlWVgtS2/Gjx9f5C5PScB3Cci0FfG0LD0ei+/C3377DV988YVyPGp0Mm4foJCRHpnZbbQgnmLFaaK04sSrRMOGDZX3WH9//h4Yra4oj2cJiJuybt26KSFkeZooP/G5J7a+Xbt2GdaFmduVnbieNpqyE7fisq61ZcuWyi5nkU+G5BlIgARKJiD2PPHTaAnr1q1T239+/PHHqFatmuWyIb59utkirTnLBsbSRLfMLjdEzVAIEvBCAkOHDlUT7mU/EgkyfWXJkiWGKIlPKztpwcmMckvFGKJGKAQJeDkB2fdYZjBIEOUndj0JycnJ2Lp1qzr2xIfbu7GeKKRtntKNliF0UXJhYWG2t3hMAiTgZAJiGpI/CcHBwXj66afV+f333+92m7jpW3byy2K74kEGSGiLc/IbzeRIQAcB+b+T1RnDhg1Tsb/66is8+uijOHbsmI6nyx/FMMpONL7FhXn5i1U4BZkbZDvowG5rYT48IwF3EqhevbrK7oYbbsBll12GzZs3q3P5/z958qTLRDGMstu5c6dLCmkZaQ0JCXFJ+kyUBEig7AT69etn9QEpJibZL9dVLT2P2+yk1dW/f39F63//+x/ef/99SPNWwqJFizBnzhwkJSUhPDwcbdq0UXN5LGv4ZJ+HadOm4eeff1Zz4+S6OCgcMWKEmuQoNjlpxVkUncCUIXExmIrTzejoaMiyGPH1xZFYhZwfJOAxAqL45M+ycZA4whUz1G233eYUmTzeshMlIwpLwp133qn85suxbCIte2bKSob33ntP9e1lt/THHnsM0lqTIG5pJN4dd9yBDz74ALfccgvENfq7776rjJ8qks2HKFFRjLIyQuLI1nRybmvTs4nOQxIgAQ8QsAwczps3z7qR/LZt21TDx/K/XxaxPK7sRGjLgIEU0uJcUFp00p+XTWtkGLtZs2ZKqckMbVnSJascli9fjhtvvBFdunRRrpck/jXXXIMffvjB2pqzhSJ7uNatWxfip1/SlDV+sgaWrtRtKfGYBIxBQCYsW9zK16hRQ7mdEtu+BOntORoMoeyKCi1dW/Ge2rRp00K3LAvy9+zZg71796rWmyWOxReXxJER1+JgiHL7888/8fzzz6uubHp6OgSi0WZ6Fyo0T0iABNRG4Y888gjkT4KYosQNlegBvcHjNrviBBVlJc1VS3PWEkcWIUuQPr2lX2+JExMTA1nHajm33Lc8K9/SgpPd1b/77ju88MILSll27txZdZ/FfsdQNgJmcvBYNgJ8yt0EBg0ahHbt2llnWejJ35AtO1Fqorik5WUbMjIy1KkoLBmwkCBxpCVoWbBvG0dFKPLRsWNHPPnkk8ohoUxs3LhxI15//fUisXjqCAHZJ5eBBNxNoGbNmjh79iwOHDigK2tDKjsZtBDbWtGlJZbzBg0aoE6dOhDvC3JNCizrXCXIudgALctVLBSkpSjeGY4ePaouiUL917/+pQZApFvMQAIk4H0EZEBy/fr1ugQ3RDdWpobIn0wuFCUn7s8HDhyIF198UY3AdOrUSSkpGZWVpSf16tVThbvyyisxa9YsNaghtjt5XrqoQ4YMsbb0LBRkCsrs2bNVK1BGbaXrJS0S6fu3aNHCEo3fJEACXkRABhtFX+gJhlB2IqgoqK+//lp5B5bNP2S+nNjuZFRWvKJK11W6oOIzyxJkE2C5LnPnZHQ2Pj5ejc7KCG5x4aGHHlLz+J599lnV/ZV5eR06dMDNN99cXHReIwESMDgByxxdPWL6ad2785PW9MR2QhzpchY3eFCepMVm54pJweK9wWILLI98Zn9Wflxk/9zatWubvagsn8EIyOwK+T8V+11pwZA2u9KELnrf1mZX9B7PSYAEzEvA62x25a0KV7TqyisTnycBEnA9gUsvvVRXq04kMYzNrjxYLCswypMGnyUBEvA+ArLzmd5gim6s2OwYSIAEfI+A7Hkhq630BFMoO9rs9FQ145CA+QjIVDNZGKAnmKIbS5udnqpmHBIwHwFD2+zEk4HMjXNmkKFnVwR6NHYFVaZJAs4j4IjNzu0tO1EgzlYiW7ZsURvzyoYeDCRAAr5DQGx20tjRM8fTFDa7SZMmudR3ve+8OiwpCXgXAZ+z2YljT7bqvOslpbQk4AwChrbZOaOARdN47rnnil7iOQmQgA8QcMRmZ4purNjsZPMdBhIgAd8i4HPz7Giz860XnKUlAQsB2uwsJPhNAiRgagK02Zm6elk4EiABCwHa7Cwk+E0CJGBqAmvWrPGttbG02Zn6fWbhSKBEAgsXLvSttbGcZ1fiu8AbJGBqArKdouz9rCe4fbmYHqEcjcN5do4SY3wSMAeBfv366S6IKebZbdq0yaHNcnXTYUQSIAFDE/A5m53sGpacnGzoSqFwJEACzifgczY72feVa2Od/yIxRRIwOgGfs9k988wzRq8TykcCJOACAo7Y7Lx2gKJPnz4ICQlRvvFkM+2goCDrHq/iIHT69OkuQMskSYAEjERAbHYJCQm6/Nl5rbKTzasPHz58EXfpzt5+++0XXecFEiAB8xEQm13r1q11KTuvHY297LLLkJ+ff1Htyc7gV1111UXXeYEESMB8BMRmV6dOHV0F81plN3LkSFSuXLlQIaVVd9NNNxW6xhMSIAHzEhCbnQxQ6gleq+xq1aqFDh06oKCgwFrOevXqsVVnpcEDEjA/AZ+ZZzdq1ChUq1ZN1Wh4eDhGjBhh/tplCUmABKwEHJln57UtOymt7CjUqVMn1bqrW7cuevfubYXAAxIgAfMTcMRm59BobFZGPk4ezkZ6Sq5hKP6r1Q3Y9VcG+lzeB9vXnTWMXCGhAaiUGIzIGIcQG0Z+CkIC3kDAJfPsfph1HAe2ZSC6UjBCwwMMxCECg/vereTZsynDMHIFh/rjx6+PIz4xBFcOq6wx8+pGtGG4UhASsCXw+++/q3l20rMrLehqdsx/PwnV6kVg0PiE0tLjfRsC7fvFI/lINua8eRj976yGiApG+pGwEZSHJOClBBYvXqzm2elRdqU2NxZOPYqaTSLRsG0FL8XhWbHjqoWgx7BqmPnSAc8KwtxJwIQEZEaGHkUnRbfbsju6Lwt5mnmu7iVRJsTkviKFRQWgcbsYbPglBS0vj3ZfxsyJBExOQJaN6g12W3bJSTkQ2xND+QlERAfi+MGs8ifEFEiABKwExGa3Z88e67m9A7uaLCM1DxXigu09z3s6CURVDERO5oUJ0DofYzQSIAE7BMRmt3nzZjsxLtyy243Nzy9A7jn+g17AVfaj/DwgO1P7YCABEnAaAbHZJSYm6krPrrLTlQIjkQAJkICHCDjNZuch+ZktCZAACegi4DSbna7cGIkESIAEPETAaTY7D8nPbEmABEhAFwHa7HRhYiQSIAFvJ0CbnbfXIOUnARLQRYA2O12YGIkESMDbCdBm5+01SPlJgAR0EZC9aDjPThcqRiIBEvBmAr169dItvt3lYrpTYUQSIAES8ACB3377Dbt379aVM5WdLkyMRAIkYEQCS5cuxd9//61LNK9Xdtdc2xVfzJiqq7CMRAIkYC4CYrOrX7++rkIZVtnt2bMLQ4ddXWohxt51H9q1u6zUeIxAAiRgPgJis2vatKmughnWEcD2HVt0FaBvn/664jESCZCA+QiIza5y5cqQPaNLCy5v2fW/thtmz56JSQ/+B737dkJaWpqSacmS73DHnSPQ96ouGDSkN956+xVkZZ13bvnRx2/jhRefwLFjR9GtR1t8/c0XmhFypzpetepX3HzLYNw1dqRKp2g3duvWzZhw/1j0H9AdV/e/Ao9OnqDSkci/r16p0ti2vbAi3aI9I/n8+ddalaa9NFQEfpAACRiCgKFsdoFBQZj/3Ww0qN8Ir77yPkJDQ/HTz8vw7PNTVPfz44++xAOTHsfPvyzDq68/pwAOH3YrBg4cqu0aVBlzZy/DNVcPQpCWjoRpn32AYUNHYeL9U9S57ceRpMP47/13QfJ847WP8MrL7yH1bAomTByLc+fOoe2lHVChQjRWrPjR9jH88styxMVVQquWl6K0NAo9yBMSIAGPEjCUzS4gIAChIaEYM/rfaNKkOQIDAzFDG1Bo2bKNula1SjW0a9sRt42+G4sXL0By8kmlEEOCQ+Dn54fo6BiEhITAX0tHQktNIfXufTXq1Lm42Tpv3leQ/B5+6CnUqlUHDRs0xoOTnsChQwfwq6bgJO/L/9VdHdvW0K+//oCuV/SEv78/7KWxes1K28d4TAIk4GECjtjsXN6NFRai5CwhNzcXO3dt1xRc4UEFUWISdu/ZaYla7LdtWkUjbN22GU0aN0dU5IUNgqpUqYrq1RK1bvAOFb1bt144cGCf+pMLO3ZuU625Hj3Ob9xhLw0ZNGG4mECNGjXUD9PFd3iFBFxLYPXq1br3oHDLAEVERKS1xJlZmSgoKMAnU9/Fp9Pet163HJw6ddJyWOy3bVpFI2RkpGv+6DegV5/CilS6sMn/pCtd1djYONW6Gz7sFtWFraYpwyaNm6nk7KVx5sypolnyXCNw8OBBVaeEQQLuJrBo0SLd+8a6RdnZAggLDVPdxSGDh6O4kdSKmiIqa4jUWnQtL2mDe8c/eFES4eER6pp0Va+4vIey2yllp3Vhr/ynVScR7KVhT9FelCEvkAAJuJyAodfGit1MbGnHj2ubb9esbYWRk5ODk8knCnVBrTd1HjRu1Aw//LgY0lKTfCzh4MH9qjVnOe/WtRfmzP0Sf/y5RmuV7EeP7hf2nrSXRsWKsZYk+E0CJGAAAoZfGzt06M1qRFZWPoiyEbvZM88+iv/cMxqZmZkKobSwTp1KxqZN63H0aJIurNdeO0Sb2nIWz73wmLILysDEp9M+wC2jr1d5WBJp3rylGul9593/qVFiW6VrL43S7ImW9PlNAiTgHgKGXxsr3cgHH3gCy39YhFvH3ICJk+5GXl4e/qdNFQkLC1OUpLVVtWp13DfhTixcNE8XORnZ/Z82veW0piRFcd459iasXbcKzzz9Kho3ujDLWkZ5ZfRV5u5ZBiYsGdhLQ6bPMJAACRiHgCPz7Py0wYISN4ZdvfCUNj9Nm+5xBbtv5a3eo3szsenXUxg4rnp5kzLc84MHD8ZLL72E2rVrG042CmRuAsuWLUP16tW1GR9NSi3oBcNWqVEZgQRIgASMReDKK6/ULZBb5tnploYRSYAESMABAitWrMDOnfbn5lqSo7KzkOA3CZCA1xFYvnw5tm7dqktudmN1YWIkEiABIxLo3LmzstnpkY3KTg8lxiEBEjAkAdrsDFkt0OYLHlWjlhkZGQaVkGKRgHcRoM3OoPVVqVIl1eROSUlREj7yyCP46quvDCotxSIB4xNwxGbHAQo31qcsYbvxxhu1ydJVVa79+/dXOyPJhOr09HS8/PLLWL9+vRslYlYk4N0ExGbXoEEDXYWgzU4XJtdEat++PeRPgqwcESU4b948tGrVCvv27cOaNWu0FR49NMeiZXeO4BrJmSoJGIMAbXbGqAeHpBBvLMOGDcOUKec9MIuC27t3L9555x2VzubNmyHrABlIgAQuEKDN7gILrz2KiorCpEmTIHY9CREREZqH5xl49dVX1fnGjRuVHzl1wg8S8FECtNmZsOLr1KmDN954A+PHj1elO3PmDMaNGwdZGyhh27ZtdKCpSPDDlwg4YrPjAIWXvhmXX3455s6dC3FeKEGa8+3atVMDHnJ+5MgR+WIgAVMTEJudHicAAsGusguN8Ic/hzCc8rKIb5kKced3SHNKgv8kIt1bCWPGjMG6des0P30J6vzZZ5+FjPZa/APKiC8DCZiNwC+//OKctbEx8cE4vu/8Xq5mg+Tu8pw4lIWI6PM7pLkyb7H1SZAurwxuyMCHBGkBig1QguzJwUACZiDw448/6l4ba7dlV6NhOLIy8pB3rkSXd2bg5ZYyJCdloV6LCxsPuSNT8fMl21BKkGks119/vTo+fvw4rr76anz++efqnB8k4K0ExJzTsGFDXeLbVXb+WkOk65AELP+C9h9dNEuItGLucdRpGo6EmucVTwnRXH750kvPb1cpSvCDDz5AYmKiyvOnn37C3XffrRSiy4VgBiTgRALdunVD48aNdaVYqkWuSq0QXDGoEj57chdado1DxYRghEa4vjumS3oDRyrIK8Bxret6/ECm1qKLQPPO0YaSViYwW1ZydO3aVbUAZYRXwtdff41du3ZhxIgRVoVoKOEpDAn8Q0BsdvIe61lFUaqykzQrVQ/Bnc/Xw58/nMa+zalISzGWsfvEiRPa7mGxCAgwjhKOiQ9EZHQQOl1dCfGJwYZ/OS2juiJonz59sHDhQmX4ldbfZ599pjbBHjhwIMLDww1fFgroOwTEZte6dWvnKTtB5x/gh7Y9jbkXxTXX3IX33ntP20Kxmu/UsgtLGhkZiSFDhlhz6NSpE7799ltlCJau8LRp09R+E2IvYSABTxKQd9DSQylNDl0tu9IS8fT9xx9/XLXsPC2HWfOvV68e7r33XmvxatSogTlz5qhfU3nRUlNTcfjwYW64YyXEA3cREJud3mB3dzG9iTCebxPo3r27+rERW9/Zs2fxxx9/oEuXLoU2KvdtQiy9qwg4YrOzOxrrKgGdne5jjz2G5ORkZyfL9HQSEHupbKUoQdxYzZ8/H7feeqs6T0pKUoMd6oQfJOBkAo7MszNFN1ZaEtnZ2U7GyOTKQkBcVYlfPkvIzc3Fww8/jDZt2qhJzYcOHUJ8fLx1/p8lHr9JoCwEHLHZmaJlR5tdWV4T9zwj9r1Zs2bhzjvvVBnu378fYmeR1p+EkydPqm9+kEBZCDgyz84Uyk5aDaGhoWVhxWfcRCA6+vw8Q/FSIX752rZtq3IWZ6WymmPLli3qXFqCDCSgl4DT1sbqzdDT8SZPnkybnacrwcH8LdMFRo8ejQ8//BAVKlRQKdx3332qFXj69GkHU2R0XyTgcza7v/76izY7L37Tq1SpYpX+9ddfV95bLF5aRo4cqdY+PvTQQ1anBtbIPPB5Aj5ns3vyySe5T4OJXnvp4spObBJeeeUVNGvWDPn5+cpd1e23366Ws5mouCxKOQj4nM1ONqixePcoBzc+akACovSuu+46NaVFRnrvuOMOpKWlKUl37twJ+aHjjmwGrDg3iSROLLZv364rN1MMUNBmp6uuTRFJlquNGjVKlUVc1bdo0UJNYpYLv//+Oz755BOICysG3yDw888/+5ayo83ON17soqWUCcwDBgyADHJIaNSokdp/d/HixepcjNdLly4FR3gVDlN+XHHFFare9RTOFJOKabPTU9Xmj1OxYkXll89SUhnxnTp1KjIyMnDttdfihx9+UM4i9Po/s6TDb+MSEPdkeoMpurG02emtbt+KJ0rtueeeU4pOSi7u6J966ils2LBBgZBur2WPDt8iY57S0mZnnrpkSZxIoHfv3soVvYzuSli1ahV69uyJlJQUdb5jxw71zQ/vIUCbnffUFSX1AAGx9UkQt1WyBaVlhzYxhwwaNEjdS09PV91fdcIPwxKgzc6wVUPBjEjAovzEI/OpU6eUiGLnE8/MV111FR544AE13UWcmjIYiwBtdsaqD0rjRQTEXZUE8czy66+/YvDgwep827Zt6NWrl9WBAbejVFg8/kGbncergAKYhUD9+vVVUWRVx4wZM1CzZk11/tVXXymffZs2bTJLUb2yHI7Y7Ewx9YTz7LzyPfU6oePi4qzLEocNG6aWsVnW8L744ovKS/O4ceNUq9DrCuelAovNzuJUorQimELZPfPMM9aXsLQC8z4JOItAy5YtrUmNHTsW0qUSj9nSBZYpLpUrV8bNN9+M4GDj7y5nLYiXHficzU6WDHFtrJe9pSYTV0Z0ZTDDMmH5xhtvhLT6LK6qnn76aSxatMhkpfZ8cXzOZifuf+jx1nMvnngkYShMQHZkE+/M0rqT0KFDBzWvT45lXp/48LNsSi7XGMpGwBGbnSlWUEirbs+ePWWjxafKRWDdunUQI76tT7pyJWjSh6+88krI9gESpBUoU1vefvttk5bWfcWSSeFNmjTRlaFptlKUZT/iAojBfQRmz56NJUuW4N1333VfpsyJBMpIwBQtOym7dKVkoTeDewi89tpr2Lp1KxVdGXHLbniyKx5D+QiIZxuZA6knmEbZWboGsocsg2sJTJgwAeJhRLZIZCgbAVmpMWXKlLI9zKesBGTDHb1rmk0x9cRSctmlSpw7iuE3JibGcpnfTiRwww03KMO7uMNmKDsBsTPLu8pQPgLyHuqdZ2cam50tMnHXLfuVcntFWyrlOxbvv+Ioc9q0aWpAonyp8WkScD8B03RjbdFVr15due6xvcbjshMQ25JMjhX7iGX5VNlT45NCgDY757wHPmmzs0UXHh6OOXPmYM2aNbaXeVwGAnPnzsV7772HhQsXcuJ2GfiV9AhtdiWRcey6z9rsbDHJrlSyC73sP2Bx4WN7n8elE3jjjTfUBNj333+/9MiM4RAB2uwcwlViZJ+32dmSkTWL0gWTGewM+glMnDgRTZs2te7kpf9JxiQBYxIwpc3OFrXMUhevKNxhypaK/WNZ1ykuzC1bFtqPzbtlIUCbXVmoXfyMz9vsiiKRNYrsyhalcvG5rC/u0qWLWtbUo0ePiyPwitMI0GbnHJSO2OxM37KzIF2wYAHXIlpgFPMtrd8RI0Zg2bJlaNiwYTExeMmZBGizcw5Nsdn53NpYPeimT5+u7FCtW7fWE91n4sybN0+5GxdPHAwkYFYCppxUbNbKckW53nzzTbXJzOTJk12RPNMsgYDY7DZv3sxVFCXw0XtZbHaygsLiR9Decz7TjbVASEtLw6RJkyynPv0tu2bJmmIqOve/BrTZOYc5bXZ2OMp2eLJj1PPPP28nlvlvDR8+HOJj7ZZbbjF/YQ1YQtrsnFMpMpBGm52DLGUUUnaO+uKLLxx80ruiyx4Jssb1gw8+0NX0967SGVtame8p/P38/FBQUKD+5Fj+ZGtGum13bf35XDfWFqdsjZeUlIR27dohKytL7Q4l3QuzhvXr10Pm0C1evJiKzgOVfN111yn7qLxzR48exbFjx9S3nAcEBHhAIu/PUmYPiF9FPcGnld3MmTMhbqHkV1aC/Lru3btXDzevizN//nzI8i/xLCxrhxncT0Ba1OKNp2iQ90/2pWVwnMDKlSshXo70BJ9VdtLXP3z4sOpCWECJH7wDBw5YTk3zLatIxHPJRx99ZJoyeWtBhg4detHWirIpj9hQGRwn4IjNzieVXffu3Yvd2SknJwfS1TNTePDBB5W3EnpwNkatSlc2MTGxkDBiRuFE7kJIdJ+Irb1Bgwa64vukspO9KoYMGYKEhARrF1Zo+fv7Y9euXbrAeUMkWREhM8xHjx7tDeL6jIxiN5XRWAnyDko9MZSNAG12OrjJHDPxunvTTTehWrVq1u6sbHHn7ft5ysbMV1xxhdojolevXjpoMIo7CUjrTt45sdWJa3a9LRN3yugteTliszPfCgptrCE5KQcZabm66ys9PR3Lly/H2rVrIVsy3nHHHV77AsoGzE899RSeeOIJ69aSMrUhMiYQFWKD4G/yQT/Zr/vk4WxkZ+bprn9PRJR/UlmmN27cuGIHLTwhU3F5ahNjEBEdiOhKxnx3VqxYoTYi1/ODYSplt2LeSWxakYLYysEIDClDD137pc3W7HaWLkZxlW/0azKiHBQUVEjM4JAAnD6ejcAgfzTtEIVWXc25GdEPM49j69pUJDaIQO45TesxlJtAYHAAUk9maz+SfmjSvgLadPfed8c0ym7Rp8e0X58QNO/ivZVR7jezlATycguwdtFJRMcFon2fiqXE9p7b+Vojbvabh9CwbQzqNI/0HsG9SNL8vAKsW3IS4ZH+uOzqOMNILjY72XNGzyqKMjR/DFNOqyBLPj+GStXDqOisRIo/CAj0Q8er45F6Ohd/LDtdfCQvvDr37cNo8a9YKjoX1p207Nr3jUdWRgFWLzLOxHtHbHZer+yO7MlCfp4fGrWr4MKqNlfSHfrFY9/WDO3F9f6u3q4N6YitEopq9ThR2h1vadvelSD/c+kp+m3irpTLkXl2Xr9JdnJSNgKC/FzJ05RpF2h6LvlINqrXD/Pq8p04mIXgMK//zfaqOijIL8Cpozlq4MLTgss8O73B69+SjNQ8xCQE6y0v4/1DoFL1EJw9ZYxf5/JUirROYxLOz1krTzp8Vj+BuGqhyhSi/wnXxZTlj1u2bNGVgdcru9xzBcjN8f7umK7acmKk7Kx85GlGZ28PWel5yMtl/buzHnMy8zXTkTHenVWrVuleCOD13Vh3VjLzIgESMBaBnj17qnl2eqSistNDiXFIgAQMSaBTp0665fL6bqzukjIiCZCA6Qj4lM3OdLXHApEACegmQJudblSMSAIk4M0EaLPz5tqj7CRAAroJ0GanGxUjkgAJeDMB2uy8ufYoOwmQgG4CtNnpRsWIJEAC3kyANjtvrj3KTgIkoJsAbXa6UTEiCZCANxOgzc6Lau+aa7viixlTvUhiikoCxiHgiM2OKyg8XG9j77oP7dpdZpViwMArkXT0iPWcBySgl4Avvjtis2vWrJkuRFwbqwuT6yL17dPfmviRpMNISTljPecBCegl4KvvDm12et+Qf+L1v7YbZs+eiUkP/ge9+3ZCWlqaurNkyXe4484R6HtVFwwa0htvvf0KsrKy1L2nn30UEyfdXSinkaMGYfD1fQpdm/LYRDz86H3YvXsnuvVoi1WrfsXNtwzGXWNHqniWbuy6P1Zj+Ihr1bVhw/vjkcn/Vce5ubn48KO3IGmLbDfdPBDzvv26UB48KR+BTZvWY8ztN6JXn8twy+jrsXbd77j7P7fi1deesyacnHwSTz/zCG648Sr06dcZY+8epW2o/of1/jfa+3PdoJ6QtOSdubr/Fao+Fy2eb40jB1u3bsaE+8ei/4DuKs6jkyfg2LGj1jjyHg4c3AsrV/4Maam98+6r6t7WbX+r5669rod6H+/6983486+16p4vvzuLFi3C5s2brfzsHbAbq9EJ1Hbjmv/dbDSo3wivvvI+QkND8dPPy/Ds81NUF/Pjj77EA5Mex8+/LMOrr5//B2jbpgP+3rJR8wl3fsu+U6eSceLEMcjuXoePHLIy37jpL1yqxbXs+DXtsw8wbOgoTLx/ijWOHLRqeSkmP/qsuvbeu5/jwUlPqOM333oJ38yegZE33Yapn3yN64eMgFwr+k+kIvPDYQKpZ1Px0MPjUSEqGm+9ORX/GTcR7773KpK0VnZA4PmOj9TxxAfuxhZNUT384FP48P0ZaNy4mfbjOA779+9VeQYHB2s/kmfx2ecf4onHX8K3c3/ElVf2xcuvPK29F8dVHGl9/ff+u9T79sZrH+GVl99D6tkUTJg4Vr03EknyzM7Owtx5X+LBB57AdQNuUD+wk7Qf1vDwCPxPe+a9dz5H06Yt8Ij2IypK2JffndWrV2PPnj2Kb2kfVHbyggUEIDQkFGNG/1vbpag5ArUXbsaMqWjZso26VrVKNbRr2xG3jb4bixcvUC9Y69btIBtq796zUzFev+EPba/ZxkphbtZ+3SUcOLBP23D7NNpe2kHbiu78hq0tNaXWu/fVqFOnnopj+ZA85WWWEBVVAREREdo/Qiq++34ubrj+JlzZow9EjmuuHohePa/CjJmfWh7ldzkI/K61tNPS03Dv+AdV3bVu1RZ3/3sC5MfLEtas+U37h9qFCf99BJdc0hqJiTVx99j/Ij6+MmbPmami+fv7Q1rhN40Yo/lXqwI57937GnVt9+4dKs68eV+pd+3hh55CrVp10FB7X+RH7dChA/h1xY8qjrwH8l4NGngjOrTvhCpVqqr38Y3XP8aECY+ibt36qFmzNm4eebva41h+cH353enduzeaN29uqSq731R2/+ARJWcJ8tLu3LVdU3AXBg7knigqCaLgEhIqq5feotg2bvwTTRo3R4sWrSGtOQkbtGsST15OS7DNx3KtpO9dmgwiS1E55JdcFGmOtsctQ/kIyGBQeHi4tlF1LWtCovCkdW8J27b/rVrmwt0SRJm1vKSNek8s1+S7bt0G1lP50ZJwVmvxSdi6bbN6R6Iio9S5fIgyq14tUTNznFeIlhu274kos9TUFLz00pMYcdMA1b29aeR1KupZ7QexuFDauyM9EDOEjh07aszr6ioKByj+wRQREWkFlpmViQJtw+xPpr6LT6e9b71uOTh16qQ6vLRNe2zavB4DBw6FtOxuHzMOIdo/yauvLVT3RdlJF9Y22OZje72444yMdHV5/H23w8/vwqZCIpuE06dPqVaEOuFHmQhIN7K4OomLi7emJy0/UQ5iM7UN0r2Nj0+wvVT8Buv/1JfU5+bNG5Rt0PYhSTv5n3fKct1WJmlV3jfhTnTs0AUPaa3CuNhKyM3LVYrPEr/od2nvjijPuLhKRR/zunOx2SUmJupq3VHZFVO9YaFhqhsyZPBw2I6WWqJWjI1Th9KVfePNF1VXVVpazVu0QmBAoLL3iCLarCnC2zQFWNZgeeEfefhp1KlduNsraZrhZS0rG2c9FxwUXGwLWexvliAtMWnpia2saLCYJ4peL+48UktHWoPSZS4aLCaMotflXGzF0rqT9yAk5PzmQmL/sxdKe3eio82xmbzY7KSHo6crS2VXzBsjL5bYU44fP1qoCypQTyafgKUb0krr7ohtZ/GSBcoGV+Gfbks9rSuzZOl3apRNWn9lDfW1ARORRaaj2HaFxQ7op3Wj5B5D+QhUrVpd8ZURUbG1SZARVdspQI0bNbOOwtvWg3SBYyue/+HTI4Wk88OPi1FN67ba1t3Bg/sR+88PaHHpSMsvVPsBtig6ibN8+SIV1dLKL/qcr7w7YrNLSCjcui7KwnJOm52FRJHvoUNvViOysrpBXsYdO7fhGW26yX/uGa0MwxI9ukK0MmqLkfoSzVZnCdLCmzN3lroXE1PRcrnUb4uyXL16Jfbt26OUqgxIfPzJO/jxp6WQX/O/1q9TI3ovvvREqekxQukEOl12ubLHvfHWi8oOKoruHW001rbV3FYbnKpfr6GaeiLTTUTJLdOUze23D8P8Bd+Unsk/Ma69dogasX3uhceUrU8GJj6d9oGa7iLvV0lBRl7lB84yODZ7zixtR63tkNaZfKenp2ujyeftg7727tBmV9Jb48D1Ky7voYb+Z8ycqmx30i1o0byVGvoPC7uwsbR0ZWd9+Zk2StfGmnrzZi3VvL2uV/S0XtNz0LBhE7TXRuDeevtlldcrL78LWWEhhu733n9NjQJLC6Bzpyu0UeK79STJOKUQqFQpHpMfeVYpOJlrV7dOfTUa++LLTyIk+HyXUVphLzz/pooz5fGJWisvUxtYqIabb74dgwcNKyWHC7dlNP1/6HdQcgAAEaZJREFU2tSm999/Xf1oyiyA2pp54pmnX0XjRk0vRCxyJPUtU45ECee9nYsOmu3u/gmT8fU309WovExXGXvnvT757jhis/PTmsHnrd1FAHvL6cpvk+Ef6I/mnfW3oLylbK6U87f5x5FYLxTNLjvfInBlXq5Me+EnR5HYKBK1m10YYHI0vxTNWC9TjyzdRDFXXHtdd9ylKZD+1wxyNDnTx/99wQlUqR2MFp2jPV7Wxx9/HK1bt0b//v1LlYVGn1IRMYKZCci0kGHDr0H7dtrqFG2OnIRZX32m5sP9q0s3MxfdFGVzxGZHZWeKKmchykpABpteeO5NfPDRmxh3z63w9/OHGPdfeP4tVKwYW9Zk+ZybCIjNTm+gstNLivFMS6BZs0vUMkHTFtDEBXPEZsfRWBO/CCwaCZidgCNrY9myM/vbwPKRgIkJ9O3bV/c8Oyo7E78ILBoJmJ1A+/b6J+2zG2v2t4HlIwETE/j++++1FS+bdJWQyk4XJkYiARIwIoG1a9di7969ukRjN1YXJkYiARIwIgHa7IxYK5SJBEjA6QRos3M6UiZIAiRgRAK02RmxVigTCZCA0wnQZud0pEyQBEjAiAR8ymYXFu6PfHBQ2dEXMSQ0AMGh3s8tsmKg5lX6gst6RzkwvuMEgsP8te0Hzm8g5fjTzn3Cp2x2FSoF4ei+TOcS9IHUDu1MR1zVYK8vaWR0II4fYP27syIP78pAxcpB7syyxLx8ymZXs1E4MtNyS4TBGxcTyDybhwhNScRW8X5lV6tJOM6eNsdOWRfXlPGu5GTmI1Rr2cUnnnds6mkJHbHZeX0/RprUrbtVxLLpRzzN3WvyXz7jCP41wPt3lhLgorBrNQ7Dr7OPeQ1/bxZU/s+6GOjdEZvdJZdcogup13sqtpTy4I5M/DDruPJYHFs5BCGaLY/hPAF/bRvGs2fOqRbQ6u9P4MaJNRETb4xuiLPqaMvvqdj+ZxpqNYlEXLUQBAWz/p3BVrbwTEvR3p1T57Bm0Qlcf28Nr+0RmEbZScWmnDyH9T+dQfLRHKSdZtfW8rKL4pfBiCq1Q9G+VywCgsxp0E/ak4Uta1KRnpqLM8eM3bUtKMjXNsrJQGRk2d3JW+rXld/BYX4IDglA1TqhaNszFkEhxnp3xGZXo0YNbXP6FqViMNVysWhtsOKKwRc2Ny619IxgKgJV64ZC/rwhJCUl4bbbxmHBggXeIK5hZRSbXW5uru8pO8PWCAUjARJwCYGrrroKlSrpsz+bqmXnEppMlARIwLAE2rZtq1s2WnF1o2JEEiABoxEQM8DGjRt1iUVlpwsTI5EACRiRwB9//IF9+/bpEo3dWF2YGIkESMCIBGizM2KtUCYSIAGnE6DNzulImSAJkIARCdBmZ8RaoUwkQAJOJ0CbndORMkESIAEjEqDNzoi1QplIgAScToA2O6cjZYIkQAJGJECbnRFrhTKRAAk4nQBtdk5HygRJgASMSIA2OyPWCmUiARJwOgHa7JyOlAmSAAkYkcC3336LDRs26BKNa2N1YWIkEiABIxL466+/sH//fl2icW2sLkyMRAIkYEQC11xzDf3ZGbFiKBMJkIBzCbRp00Z3guzG6kbFiCRAAkYjQJud0WqE8pAACbiEAG12LsHKREmABIxGgDY7o9UI5SEBEnAJAdrsXIKViZIACRiNAG12RqsRykMCRQhUrFgR1atXR15eXpE7PHWEwPr163HunL4N0f0KtOBI4oxLAiTgPAKy3GndunXOS9CHUkpJSUFERAQCA/VNF+bUEx96OVhU4xFYuXIlOnXqZDzBDC7R0qVLkZaWplvRSXGo7AxeqRTP3ARCQkKwePFidO3a1dwFdWLpHnjgAYSHhyszgCPJshvrCC3GJQEXETh58iSGDx+uFJ+LsvD5ZNmy8/lXgACMQKBSpUr45JNPIPPGGIonMHfuXGzatKn4mzquUtnpgMQoJOAOAtWqVcMbb7yBQYMGuSM7r8rj/fffR1RUFFq0aFFmudmNLTM6PkgCriGwY8cOTJkyBTNmzHBNBj6aKlt2PlrxLLZxCTRs2BAPP/wwRo0aZVwh3STZnDlzsGzZMqfkxpadUzAyERJwPgHZTOa9996DdOF8MSxatAh+fn7o3bu3U4pPZecUjEyEBFxDYNWqVZg+fTrefPNN12TgQ6myG+tDlc2ieh+Byy67DEOGDMF9993nfcKXUWJZ7/rxxx+X8emSH2PLrmQ2vEMChiEgKwaWL1+O5557zjAyuUIQWet66tQpdO/e3enJU9k5HSkTJAHXEFiwYAHWrl2Lxx9/3DUZmDxVdmNNXsEsnnkIXH311WjZsiWefvpp8xTqn5IsXLgQjzzyiEvLxZadS/EycRJwPoGZM2fi4MGDuP/++52fuAdSlLLIdohdunRxae5Udi7Fy8RJwDUEpk2bhtOnT+Oee+5xTQZuSjUrKwsZGRmIjY11eY7sxrocMTMgAecTGDlypPLl9u677xZKvGfPnih6rVAED54UHXQQ++P48ePdouik2FR2Hqx8Zk0C5SEwZswY5enYMk2jV69eqrUnPvKMFl588UWIs01LV1WOxemmOxUzlZ3R3grKQwIOEPj3v/+tlEjnzp3VlA15VNxFbd261YFUXB91zZo1ajWEdFtF4R05cgStW7d2fcY2OVDZ2cDgIQl4IwGZkpKdnW0V/cSJE5CVF0YJf/75J86cOWMVRxTerbfeaj131wGVnbtIMx8ScAEBaSVJl7BoWLFiRdFLHjv/+eefra1OixCySU7Hjh0tp275prJzC2ZmQgLOJ3DLLbco474sli8akpKScODAgaKXPXJe3IZCll3V+vXr5zaZ9G3L4zZxmBEJkIBeAuLZePXq1ZBWnHhIkakox44dg7+/P5KTk9W9mjVr6k3OJfHEs7DIYlHIQUFBEK/MdevWVd5M3KnsOM/OJVXMREnANQRk49OM1FxkpefDdhdUaSlt2LBBbcu4e/dupWBE0U2ePNk1guhM9csvv4Qs7BcFl5CQABlIkVUgMTEx1hREEQaF+COiQgACgi5upVojlvOAyq6cAPk4CbiSQHpKLnZvTMfO9elITspGTmYegsMCEFUpFFlnc4rNWhSiKL/AwIBi77v7Yu65XPgHBGgtzuIVmX9QAHIyclXZAgL9kFAzDNXqhqJBqwjEVQ12mrhUdk5DyYRIwHkEjh/Mxu8Lz+DovgxExoWjQkIEQisEIzDYGArMeSUtnFLeuXxN6eUi9Vg60pLTERMfjBado9CwdWThiGU4o7IrAzQ+QgKuInAuqwDfTT2KU8fOoUrDSgiPCXFVVl6R7jlN8R3beQrIz0W36+NRvV5omeWmsiszOj5IAs4lkLQ3Cws/PY642jGIrhzh3MS9PLXM1GycOXIWjVqGok336DKVhsquTNj4EAk4l8DujRn4dV4yaret5tyETZba0e3JiK0E9BqR4HDJOM/OYWR8gAScS2Dn+gz8viiFik4H1iqN4nD6lB9WfHtaR+zCUajsCvPgGQm4lYB0XVcuSEb1Fo63VNwqqIEyq9wgFkkH87B6kWMKj8rOQJVIUXyLwLlsbTDio6OofSm7ro7WfHzditizORt7/87Q/SiVnW5UjEgCziWw4KMkJDSIc26iPpRaZa1Lu+jTJN0lprLTjYoRScB5BKT7mpKcp82fC3deoj6Wkn+gP+JqROvuzlLZ+dgLwuIag8Cq70+zVeeEqkioXxGbf0tFQV7piVHZlc6IMUjAqQTOnDiH08dyEB5tngnDqaknMeHRDti89WenstKTWFhMKLasSS01KpVdqYgYgQScS2DvpnREVmL31VlUozSWO/9KKzU5KrtSETECCTiXwM4NaWq9q3NT9d3UouLDcWhn6aOy9Gfnu+8IS+4hAilaNza+oWe6sNLdnL/4dezdvx7pGWdQtXID9Os1FvXrXKpoJB3bhZffHI47Rr2JX1bNwP4DmzSPJYFo1bwn+vcdr3zlScRVa2Zj+S9TkZZ+GjWqN0Xv7rd7iOb5bCskhOLYgWxUrlkyVyo7j1YRM/c1AtmZ+Zr7pQL4leDuyJU8xO3TB9PuQc65LAwb/DiiIuOwcvVX+HDaeNx71zRUTqiDAP8gJcLc71/B4P6TULtmS+zcvRbvfzoOdWq1RMvmPbBn31/4Zv7zuKLzcFzWbiCSTx3C/EWvu1L0UtP2D/CHuMMCSlZ27MaWipERSMB5BMTxpvij80TYvnMVpOU25NqHULd2a8RXqqm11u5FTHRlrPj9SyWSeDmW0Kr5lZpya6U8DDes3x4VY6rg4KEt6t4f6xcqRdmv579RKS4RjRp0RMd2A9Q9T32I66t0ja29QGVnjw7vkYCTCWRl5CMytuxuisojzsHDWxAQEIR6ddpYkxHlJorvcNIO6zU5qFa1YaHz0NAoZGadVdeOndiHGolNtbQuKG1Jw5MhKDQYeec0r6V2AruxduDwFgk4m0B4VABST2Rqc+ycnXLp6WVmpWld6HN44PF/FYqcn5+H6AqF1+YGBV7cHSzAeWWSnZ2Oilpr0DaEBHt2dDknIwdBoWG2Il10TGV3ERJeIAHXEYioEKjcj7suh5JTDguLQnBQKMbf9elFkfz9L7TSLrpZ5EJwcBiyz2UWumpp9RW66MYTcf0eqbG1F+zftfck75EACThMIDDYDzEJIcjXBin8A4rfk8HhRHU+IKOmMjgh7bPK8bWtT506fUTZ4KwXSjmIj6uJHbtXqw1/LLuG7dqztpSnXHs7KMgf4dqGPfYCbXb26PAeCbiAgPxTpiUXbhm5IJuLkmxUvwOqVWmIGV9Pwa69f0CU3J8bF+OVt2/CqrWzL4pf0oXWLXsj9aw2hUUbgZUBj42bf8C6vxaWFN3l12XfijPHMhGfeHHX2zZztuxsafCYBNxAoGHrCGxYmeF2JwAB2ny5225+DQs0JTVt5oPIyclEbEw19Oo2Bpd3ulF3yUVpXtPnHvy8crqaupJYrTGuH/AQ/vfOSM0maH9EVHcmDkQ8eyIDtZqW7saebtkdgMqoJOAMAplp+Zjx4kHU7ZjojOR8Po2kbSfRvkck6l1iX+GxG+vzrwoBuJtAWKQ/qtQOxZmk0tdzuls2b8vvXFYe0pMzSlV0Ui52Y72tdimvKQhcfl2cat3FVC19P9TJz/REfkF+ieWWqSP+fppxvpTxjof/Ow9hoaXnV2JGOm98Mv1+7N73p93YebnnEBB4frVGcRGDg8IweeKC4m4VunZizyl0ubZSoWslnbAbWxIZXicBFxP45ZuTOHkqELGJUXZzkvWs9oLYyfy1Cb5+pWi7qKg4tSLCXlrOuJeRkYrc3By7SWVr9sIQbQpLicHPDxU0ee2F7DTNVdaBkxj6X33mACo7ezR5jwRcTODjx/YhsUVVBIezk+Uo6p0rDuDG+2sgMkYfO9rsHCXM+CTgRAI3PVQLu34/5MQUfSOpQxuP4sobK+tWdEKFLTvfeDdYSgMTSDuTh9lvJ6Fm66oGltI4oh1YfxTdBsWhRkPH1hizZWecOqQkPkogMiYAA+6ogs1L9iIn/ZyPUtBX7L1rD+PSrlEOKzpJnS07fYwZiwTcQuCrVw8jzy8YshG0ZqNn+IdA8oFUZKdkaF3XSkioYX+lREnQqOxKIsPrJOAhAmuXnsGahSdRpWGstsoiAkFh+gzwHhLXZdnm5xbgrLas7tiOk6jbIhLdro/X3EqVPTsqu7Kz45Mk4FICqxed1rYJTNG8GvurDXpCo0IQFBKAwJBA7U/7ry+w77/NpcI5M3GtBSvrW3Oz83BO/rJycfZ4GjJSstG0fQza9oxBRHQ5tNw/slLZObPSmBYJuIDAycM52LUxHUe1jbXTz+YiMy0XYVFBSDmW7YLc3J9kUKi/0tthkQEIjwrUuqmhqNMsDIkN7MzDK4OYVHZlgMZHSIAEvI8AR2O9r84oMQmQQBkIUNmVARofIQES8D4CVHbeV2eUmARIoAwEqOzKAI2PkAAJeB8BKjvvqzNKTAIkUAYCVHZlgMZHSIAEvI8AlZ331RklJgESKAOB/wOu5n9bUE2fLAAAAABJRU5ErkJggg==)"
      ],
      "metadata": {
        "id": "lLc4NwngK5Af"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code runs the compiled workflow, starting with the initial state containing the user query formatted as a `HumanMessage`. The workflow executes node by node according to the defined edges until it reaches `END`. The final state is returned in result."
      ],
      "metadata": {
        "id": "Tc-l396xfsl8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us look at an example of the internal workings of this agent in action with a few examples."
      ],
      "metadata": {
        "id": "y701_JB-GK30"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 1**"
      ],
      "metadata": {
        "id": "9vJnyoQHImkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = \"what was the revenue from automobile operations in 2022?\"\n",
        "result = agent_workflow.invoke({\"messages\": [HumanMessage(content=user_query)]})"
      ],
      "metadata": {
        "id": "ARaUZtCxBFWT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03e87a42-e2d7-4d30-8cd4-4541d4c89388"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---PLAN RETRIEVAL---\n",
            "---CHECK RELEVANCE---\n",
            "--- Relevance Score: yes ---\n",
            "---DECISION: DOCS RELEVANT---\n",
            "---GENERATE ANSWER---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result['messages'][-1].content)"
      ],
      "metadata": {
        "id": "GTrywilRBU-s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c05e80e-44d7-46cf-e0f9-63e9f549b5af"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total revenue from automobile operations in 2022 was $82,419 million. This includes automotive sales, regulatory credits, and leasing revenues.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 2**"
      ],
      "metadata": {
        "id": "ZUdHbFDyIo-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = \"Were there specific mentions of Cybertruck manufacturing challenges in the 2022 10-K risk factors?\"\n",
        "result = agent_workflow.invoke({\"messages\": [HumanMessage(content=user_query)]})"
      ],
      "metadata": {
        "id": "rYf-1hZ-r9yO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a35e2c49-a24c-4d21-f989-fd26c2da7af7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---PLAN RETRIEVAL---\n",
            "---CHECK RELEVANCE---\n",
            "--- Relevance Score: yes ---\n",
            "---DECISION: DOCS RELEVANT---\n",
            "---GENERATE ANSWER---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result['messages'][-1].content)"
      ],
      "metadata": {
        "id": "D1AQ2l88HG-H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee374954-48fc-49fe-8056-eb3d07c24ed3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes, the 2022 10-K risk factors specifically mentioned potential delays and complications in launching and ramping production of the Cybertruck, along with other new vehicles. These challenges could arise from design, manufacturing, and regulatory issues. The report highlighted that such delays could adversely affect the company's business and financial condition.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 3**\n",
        "\n",
        "Let us look at an example where the tool execution should potentially be skipped. This will test the edge case where the conditional edge between `plan` and `END` is activated."
      ],
      "metadata": {
        "id": "FxvlPkLaIq96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = \"Tell me about the design philosophy behind the Cybertruck.\"\n",
        "result = agent_workflow.invoke({\"messages\": [HumanMessage(content=user_query)]})"
      ],
      "metadata": {
        "id": "QKMlwkFxI8sj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10d36729-7704-4656-9025-751afc549aab"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---PLAN RETRIEVAL---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result['messages'][-1].content)"
      ],
      "metadata": {
        "id": "M5U28uK8JC8I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a56fcfc-0eac-4af6-d7ab-d7cd48158f27"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The design philosophy behind the Tesla Cybertruck is characterized by its bold, unconventional aesthetics and a focus on utility, durability, and performance. Here are some key aspects of its design philosophy:\n",
            "\n",
            "1. **Futuristic Aesthetics**: The Cybertruck features a geometric, angular design that departs from traditional truck shapes. This design is intended to evoke a sense of the future and innovation.\n",
            "\n",
            "2. **Material Choice**: The body of the Cybertruck is made from ultra-hard 30X cold-rolled stainless steel, which is intended to provide superior durability and resistance to dents, corrosion, and damage. This choice reflects a commitment to building a vehicle that can withstand tough conditions.\n",
            "\n",
            "3. **Armor Glass**: The Cybertruck is equipped with Tesla's \"armor glass,\" which is designed to be shatter-resistant. This feature aligns with the overall philosophy of creating a robust and resilient vehicle.\n",
            "\n",
            "4. **Functionality and Versatility**: The design emphasizes utility, with a spacious interior and a versatile bed that can accommodate various types of cargo. The Cybertruck is designed to be a practical vehicle for both work and recreation.\n",
            "\n",
            "5. **Performance**: The Cybertruck is built to deliver high performance, with impressive acceleration, towing capacity, and off-road capabilities. The design supports these performance goals through its aerodynamic shape and weight distribution.\n",
            "\n",
            "6. **Sustainability**: As with all Tesla vehicles, the Cybertruck is designed with sustainability in mind, aiming to reduce the environmental impact of transportation.\n",
            "\n",
            "Overall, the Cybertruck's design philosophy reflects Tesla's commitment to innovation, durability, and performance, while also challenging conventional automotive design norms.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To understand why there was no relevance check, look closely at the retriever_tool description:\n",
        "\n",
        "```\n",
        "\"\"\"\n",
        "Search and return information mentioned in Tesla 10K documents from 2019 to 2023.\n",
        "Use this tool ONLY to find specific financial figures, operational details, risks,\n",
        "or other factual data directly reported in Tesla's 10-K filings.\n",
        "Do NOT use this tool for general knowledge questions about Tesla.\n",
        "\"\"\"\n",
        "```"
      ],
      "metadata": {
        "id": "3spqC_QAJI7b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So why wasn't relevance check triggered here?\n",
        "\n",
        "- The LLM (gpt-4o-mini) analyzes the query \"Tell me about the design philosophy behind the Cybertruck.\" against the tool description. It correctly determines that \"design philosophy\" is likely a general knowledge question about Tesla/Cybertruck, not the specific financial/operational/risk data found in 10-K filings that the tool description explicitly restricts itself to. The instruction \"Do NOT use this tool for general knowledge questions about Tesla\" is crucial here.\n",
        "\n",
        "- Skipping the Tool: Because the query doesn't match the tool's designated purpose, the LLM decides not to invoke the retriever_tool. Instead of outputting a message with a tool_call, it outputs a standard `AIMessage` containing the answer based on its own pre-trained general knowledge.\n",
        "\n",
        "- Graph Flow (`tools_condition`): The plan node returns this direct AIMessage. The `tools_condition` edge checks this message. Since there's no `tool_call` present, the condition evaluates to `END`.\n",
        "\n",
        "- Bypassing Retrieval and Relevance: The workflow transitions directly from plan to `END`, completely bypassing the retrieve node and therefore also the `grade_documents` relevance check node."
      ],
      "metadata": {
        "id": "aj_ZmiKwJQmV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above example underscores the importance of tool descriptions in guiding the behavior of the agent."
      ],
      "metadata": {
        "id": "H5a-dCEMJpx3"
      }
    }
  ]
}